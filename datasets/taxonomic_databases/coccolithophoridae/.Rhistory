par(mfrow = c(3, 3))
if (scr %in% c("prymnesiophycae","foraminifera","radiolaria",
"coccolithophoridae")) {tp = -15:0} else {tp = -5:0} #optimal delay (tp) values
#test with several delay values
for (i in 1:NROW(comb)) {
vars <- c(comb[i,1], comb[i,2])
params <- expand.grid(lib_column = vars, target_column = vars, tp = tp) # generate all combinations of lib_column, target_column, tp
params <- params[params$lib_column != params$target_column, ] # throw out cases where lib == target
params$E <- best_E[as.vector(params$lib_column)] #embedding dimension
output <- do.call(rbind, lapply(seq_len(NROW(params)), function(i) {
ccm(envsub, E = params$E[i], lib_sizes = NROW(envsub),
random_libs = FALSE, lib_column = params$lib_column[i],
target_column = params$target_column[i],
tp = params$tp[i], silent = TRUE)}))
plot(output$tp[output$lib_column == comb[i,1]],
output$rho[output$lib_column == comb[i,1]],
xlab = "tp", ylab = "Cross Map Skill (rho)", col = "green",
ylim = c(0,1), type = "l", lwd = 2)
lines(output$tp[output$lib_column == comb[i,2]],
output$rho[output$lib_column == comb[i,2]], col = "purple",
lwd = 2)
legend(x = "topleft", col = c("green", "purple"), lwd = 2,
legend = c(paste(comb[i,1]," xmap ",comb[i,2]), paste(comb[i,2],
" xmap ",comb[i,1])),
inset = 0.02, bty = "n", cex = 0.8)
#fill matrices
ccm_rho_matrix[comb[i,1], comb[i,2]] <- max(output$rho[output$lib_column == comb[i,1]],
na.rm=TRUE)
ccm_tp_matrix[comb[i,1], comb[i,2]] <- output$tp[output$rho == ccm_rho_matrix[comb[i,1],
comb[i,2]] & !is.na(output$rho)]
}
#ccm analyses and significance test with surrogate data
for (i in 1:NROW(comb)) {
out_temp <- ccm(envsub, E = best_E[comb[i,1]], lib_column = comb[i,1], #ccm
target_column = comb[i,2], lib_sizes = NROW(envsub),
tp = ccm_tp_matrix[comb[i,1], comb[i,2]],
replace = FALSE, silent = TRUE)
ccm_rho_matrix[comb[i,1], comb[i,2]] <- out_temp$rho #fill matrix
#significance test
num_surr <- 1000 #number of runs
partialdat <- data.frame(envsub[comb[i,1]],envsub[comb[i,2]])
names(partialdat) <-comb[i,]
partialdat <- partialdat[complete.cases(partialdat), ]
surr_a <- make_surrogate_data(partialdat[comb[i,2]], method = "ebisuzaki",
num_surr = num_surr)
ccm_rho_surr <- numeric(num_surr)
for (j in 1:num_surr) {
ccm_rho_surr[j] <- ccm(cbind(partialdat[comb[i,1]], surr_a[,j]),
E = best_E[comb[i,1]], lib_column = 1,
tp = ccm_tp_matrix[comb[i,1], comb[i,2]],
target_column = 2, lib_sizes = NROW(envsub),
replace = FALSE, silent = TRUE)$rho
}
#p-values computation
ccm_rho_pvalues_matrix[comb[i,1], comb[i,2]] <- (sum(ccm_rho_matrix[comb[i,1],
comb[i,2]] < ccm_rho_surr) + 1) / (length(ccm_rho_surr) + 1)
}
#convergence test
for (i in 1:NROW(comb)) {
#cross-maps
inv_xmap_no <- ccm(envsub, lib_column = comb[i,1], target_column = comb[i,2], #lib_column cause
E = best_E[comb[i,1]], tp = ccm_tp_matrix[comb[i,1], comb[i,2]], silent = TRUE)                       #target_column consequence
no_xmap_inv <- ccm(envsub, lib_column = comb[i,2], target_column = comb[i,1],
E = best_E[comb[i,2]], tp = ccm_tp_matrix[comb[i,1], comb[i,2]], silent = TRUE)
inv_xmap_no_means <- ccm_means(inv_xmap_no) #means for different library sizes
no_xmap_inv_means <- ccm_means(no_xmap_inv)#moyennes pour diffÃ©rentes library sizes
#convergence test
kendallconv <- cor.test(inv_xmap_no_means$lib_size, pmax(0, inv_xmap_no_means$rho), method = "kendall")
if (is.na(kendallconv$estimate) | kendallconv$estimate < 0) {ccm_rho_converg[comb[i,1], comb[i,2]] <- 0.99
} else  {ccm_rho_converg[comb[i,1], comb[i,2]] <- kendallconv$p.value}
}
ccm_rho_ptot <- ccm_rho_pvalues_matrix
for (i in NROW(ccm_rho_ptot)) {for (j in NCOL(ccm_rho_ptot)) {
ccm_rho_ptot[i,j] <- max(ccm_rho_pvalues_matrix[i,j],ccm_rho_converg[i,j])
}}
#save matrices
write.table(ccm_rho_matrix,paste("rho_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
write.table(ccm_rho_pvalues_matrix,paste("pval_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
write.table(ccm_rho_converg,paste("converg_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
write.table(ccm_tp_matrix,paste("tp_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
}
View(envsub)
envsub <- env[,2:NCOL(env)-1]
envsub <- env[,2:NCOL(env)]
envsub <- rawdataset <- as.data.frame(scale(envsub))
causalvars <- names(envsub)
effectvars <- causalvars[1:3]
simplex_out <- lapply(causalvars, function(var) {
simplex(envsub[,var], E = 0:10)
})
names(simplex_out) <- causalvars
par(mfrow = c(3, 3))
for (var in names(simplex_out)) {
plot(simplex_out[[var]]$E, simplex_out[[var]]$rho, type = "l",
xlab = "Embedding Dimension (E)",
ylab = "Forecast Skill (rho)", main = var)
}
best_E <- sapply(simplex_out, function(df) {
df$E[which.max(df$rho)]
})
ccm_rho_matrix <- matrix(NA, nrow = length(causalvars), ncol = length(effectvars), dimnames = list(causalvars, effectvars))
ccm_rho_pvalues_matrix <- matrix(NA, nrow = length(causalvars), ncol = length(effectvars), dimnames = list(causalvars, effectvars))
ccm_rho_converg <- matrix(NA, nrow = length(causalvars), ncol = length(effectvars), dimnames = list(causalvars, effectvars))
ccm_tp_matrix <- matrix(NA, nrow = length(causalvars), ncol = length(effectvars), dimnames = list(causalvars, effectvars))
comb <- expand.grid(causalvars, effectvars, stringsAsFactors = FALSE)
comb <- comb[comb$Var1 != comb$Var2,]
par(mfrow = c(3, 3))
if (scr %in% c("prymnesiophycae","foraminifera","radiolaria",
"coccolithophoridae")) {tp = -15:0} else {tp = -5:0} #optimal delay (tp) values
#test with several delay values
for (i in 1:NROW(comb)) {
vars <- c(comb[i,1], comb[i,2])
params <- expand.grid(lib_column = vars, target_column = vars, tp = tp) # generate all combinations of lib_column, target_column, tp
params <- params[params$lib_column != params$target_column, ] # throw out cases where lib == target
params$E <- best_E[as.vector(params$lib_column)] #embedding dimension
output <- do.call(rbind, lapply(seq_len(NROW(params)), function(i) {
ccm(envsub, E = params$E[i], lib_sizes = NROW(envsub),
random_libs = FALSE, lib_column = params$lib_column[i],
target_column = params$target_column[i],
tp = params$tp[i], silent = TRUE)}))
plot(output$tp[output$lib_column == comb[i,1]],
output$rho[output$lib_column == comb[i,1]],
xlab = "tp", ylab = "Cross Map Skill (rho)", col = "green",
ylim = c(0,1), type = "l", lwd = 2, main = paste(comb[i,1],"<->",comb[i,2]))
lines(output$tp[output$lib_column == comb[i,2]],
output$rho[output$lib_column == comb[i,2]], col = "purple",
lwd = 2)
legend(x = "topleft", col = c("green", "purple"), lwd = 2,
legend = c(paste(comb[i,1]," xmap ",comb[i,2]), paste(comb[i,2],
" xmap ",comb[i,1])),
inset = 0.02, bty = "n", cex = 0.8)
#fill matrices
ccm_rho_matrix[comb[i,1], comb[i,2]] <- max(output$rho[output$lib_column == comb[i,1]],
na.rm=TRUE)
ccm_tp_matrix[comb[i,1], comb[i,2]] <- output$tp[output$rho == ccm_rho_matrix[comb[i,1],
comb[i,2]] & !is.na(output$rho)]
}
#ccm analyses and significance test with surrogate data
for (i in 1:NROW(comb)) {
out_temp <- ccm(envsub, E = best_E[comb[i,1]], lib_column = comb[i,1], #ccm
target_column = comb[i,2], lib_sizes = NROW(envsub),
tp = ccm_tp_matrix[comb[i,1], comb[i,2]],
replace = FALSE, silent = TRUE)
ccm_rho_matrix[comb[i,1], comb[i,2]] <- out_temp$rho #fill matrix
#significance test
num_surr <- 1000 #number of runs
partialdat <- data.frame(envsub[comb[i,1]],envsub[comb[i,2]])
names(partialdat) <-comb[i,]
partialdat <- partialdat[complete.cases(partialdat), ]
surr_a <- make_surrogate_data(partialdat[comb[i,2]], method = "ebisuzaki",
num_surr = num_surr)
ccm_rho_surr <- numeric(num_surr)
for (j in 1:num_surr) {
ccm_rho_surr[j] <- ccm(cbind(partialdat[comb[i,1]], surr_a[,j]),
E = best_E[comb[i,1]], lib_column = 1,
tp = ccm_tp_matrix[comb[i,1], comb[i,2]],
target_column = 2, lib_sizes = NROW(envsub),
replace = FALSE, silent = TRUE)$rho
}
#p-values computation
ccm_rho_pvalues_matrix[comb[i,1], comb[i,2]] <- (sum(ccm_rho_matrix[comb[i,1],
comb[i,2]] < ccm_rho_surr) + 1) / (length(ccm_rho_surr) + 1)
}
#convergence test
for (i in 1:NROW(comb)) {
#cross-maps
inv_xmap_no <- ccm(envsub, lib_column = comb[i,1], target_column = comb[i,2], #lib_column cause
E = best_E[comb[i,1]], tp = ccm_tp_matrix[comb[i,1], comb[i,2]], silent = TRUE)                       #target_column consequence
no_xmap_inv <- ccm(envsub, lib_column = comb[i,2], target_column = comb[i,1],
E = best_E[comb[i,2]], tp = ccm_tp_matrix[comb[i,1], comb[i,2]], silent = TRUE)
inv_xmap_no_means <- ccm_means(inv_xmap_no) #means for different library sizes
no_xmap_inv_means <- ccm_means(no_xmap_inv)#moyennes pour diffÃ©rentes library sizes
#convergence test
kendallconv <- cor.test(inv_xmap_no_means$lib_size, pmax(0, inv_xmap_no_means$rho), method = "kendall")
if (is.na(kendallconv$estimate) | kendallconv$estimate < 0) {ccm_rho_converg[comb[i,1], comb[i,2]] <- 0.99
} else  {ccm_rho_converg[comb[i,1], comb[i,2]] <- kendallconv$p.value}
}
ccm_rho_ptot <- ccm_rho_pvalues_matrix
for (i in NROW(ccm_rho_ptot)) {for (j in NCOL(ccm_rho_ptot)) {
ccm_rho_ptot[i,j] <- max(ccm_rho_pvalues_matrix[i,j],ccm_rho_converg[i,j])
}}
#save matrices
write.table(ccm_rho_matrix,paste("rho_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
write.table(ccm_rho_pvalues_matrix,paste("pval_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
write.table(ccm_rho_converg,paste("converg_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
write.table(ccm_tp_matrix,paste("tp_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
View(envsub)
library(divDyn)
library(bestNormalize)
qsqs <- 0.8 #set quorum value for sqs subsampling
#divdyn dataframes
data(stages)
data(stratkeys)
data(keys)
data(tens)
#taxonomic database
taxdb <- read.delim("vrineau_2020-07-30_08-26-10 radiolarians.csv",
stringsAsFactors = FALSE)
gstages_path <- paste(substr(getSourceEditorContext()$path,1,35),
"datasets/environmental_databases/", sep="")
gstages <- read.csv(paste(gstages_path,"gstages.micro.csv", sep=""),
sep = ",", na.strings = "", stringsAsFactors = FALSE) #taxonomic database
names(taxdb)[2] <- "genus"
names(taxdb)[19] <- "age"
taxdb <- taxdb[!is.na(taxdb$age),]
#database datation
taxdb$stg <- rep(NA, nrow(taxdb))
#datation par stg bin
for (i in 1:nrow(taxdb)) {
for (j in 1:nrow(gstages)) {
if (taxdb$age[i] < gstages$bottom[j] & taxdb$age[i] > gstages$top[j]) {
taxdb$stg[i] <- gstages$stg[j]
break
}
}
}
taxdb$stg[taxdb$age == 0] <- gstages$stg[length(gstages$stg)]
#diversity sqs subsampling and rates calculation
samptax <-binstat(taxdb, tax="genus", bin="stg",coll="Site", ref="Source",
duplicates=TRUE,indices=TRUE, noNAStart=TRUE)
dd <-divDyn(taxdb, bin="stg", tax="genus", noNAStart=TRUE)
sqsquorum <-subsample(taxdb, iter=500, q=qsqs, tax="genus", bin="stg",
type="sqs", noNAStart=TRUE)
colnames(sqsquorum)[1] <- "stg"
#environmental datasets
env_path <- paste(substr(getSourceEditorContext()$path,1,35), "datasets/environmental_databases/", sep="")
T.scotese.dataset1    <- read.csv(paste(env_path,"T.scotese.dataset.micro.csv", sep=""),sep = ",", na.strings = "", stringsAsFactors = FALSE)
C.ogg.dataset1        <- read.csv(paste(env_path,"C.ogg.dataset.micro.csv", sep=""), sep = ",", na.strings = "", stringsAsFactors = FALSE)
S.macarthur.dataset1  <- read.csv(paste(env_path,"S.macarthur.dataset.micro.csv", sep=""), sep = ",", na.strings = "", stringsAsFactors = FALSE)
Sf.paytan.dataset1    <- read.csv(paste(env_path,"Sf.paytan.dataset.micro.csv", sep=""), sep = ",", na.strings = "", stringsAsFactors = FALSE)
colnames(C.ogg.dataset1)[2] <- "C.veizer"
colnames(T.scotese.dataset1)[2] <- "T.scotese"
colnames(S.macarthur.dataset1)[2] <- "S.macarthur"
colnames(Sf.paytan.dataset1)[2] <- "Sf.paytan"
#merging
non_log_env <- Reduce(function(x,y) merge(x,y,by = "stg", all.x = TRUE, all.y = FALSE), #Il faut choisir LOESS ou non ici (5 ou 6)
list(sqsquorum[,c(1,13,28,29)],
T.scotese.dataset1,
C.ogg.dataset1,
S.macarthur.dataset1,
Sf.paytan.dataset1
))
#NA deletion
widestts <- c()
for (i in 1:nrow(non_log_env)) {
tryts <- c()
for (j in i:nrow(non_log_env)) {
if (!is.na(non_log_env$divCSIB[j])) {
tryts <- c(tryts,j)
} else {
break}
}
if (length(tryts) > length(widestts)) {widestts <- tryts}
}
non_log_env <- non_log_env[widestts,]
#log
env_detrend <- non_log_env
env_detrend$divCSIB <- log(non_log_env$divCSIB)
env <- env_detrend
#remove trend
env$T.scotese   <- c(NA,NA,diff(env_detrend$T.scotese, differences = 2))
#remove trend
env$T.scotese   <- c(NA,NA,diff(env_detrend$T.scotese, differences = 2))
env$S.macarthur <- c(NA,NA,diff(env_detrend$S.macarthur, differences = 2))
env$Sf.paytan   <- c(NA,NA,diff(env_detrend$Sf.paytan, differences = 2))
env$C.veizer    <- c(NA,diff(env_detrend$C.veizer, differences = 1))
env$divCSIB     <- c(NA,diff(env_detrend$divCSIB, differences = 1))
#outlier deletion
env$S.macarthur[1] <- NA #outlier deletion
env$T.scotese[1] <- NA #outlier deletion
#ordernorm transformation and scaling
for (j in 2:ncol(env)) {
orderNorm_obj <- orderNorm(env[,j])
env[,j] <- scale(predict(orderNorm_obj))
}
colnames(env) <- c("stage","diversity","extinction","origination","temperature",
"carbon","strontium","sulfur")
#save
write.csv(env,"env_dataframe.csv", row.names = FALSE)
taxdbnona <- taxdb
save(taxdbnona,env,non_log_env,qsqs,file = "savevar.RData")
taxdb_path <- paste(substr(getSourceEditorContext()$path,1,35),
"datasets/taxonomic_databases/",scr,"/", sep="")
setwd(dir = taxdb_path) #set path
load("savevar.RData")
envsub <- env[,2:NCOL(env)]
envsub <- rawdataset <- as.data.frame(scale(envsub))
causalvars <- names(envsub)
effectvars <- causalvars[1:3]
simplex_out <- lapply(causalvars, function(var) {
simplex(envsub[,var], E = 0:10)
})
names(simplex_out) <- causalvars
par(mfrow = c(3, 3))
for (var in names(simplex_out)) {
plot(simplex_out[[var]]$E, simplex_out[[var]]$rho, type = "l",
xlab = "Embedding Dimension (E)",
ylab = "Forecast Skill (rho)", main = var)
}
best_E <- sapply(simplex_out, function(df) {
df$E[which.max(df$rho)]
})
ccm_rho_matrix <- matrix(NA, nrow = length(causalvars), ncol = length(effectvars), dimnames = list(causalvars, effectvars))
ccm_rho_pvalues_matrix <- matrix(NA, nrow = length(causalvars), ncol = length(effectvars), dimnames = list(causalvars, effectvars))
ccm_rho_converg <- matrix(NA, nrow = length(causalvars), ncol = length(effectvars), dimnames = list(causalvars, effectvars))
ccm_tp_matrix <- matrix(NA, nrow = length(causalvars), ncol = length(effectvars), dimnames = list(causalvars, effectvars))
comb <- expand.grid(causalvars, effectvars, stringsAsFactors = FALSE)
comb <- comb[comb$Var1 != comb$Var2,]
par(mfrow = c(3, 3))
if (scr %in% c("prymnesiophycae","foraminifera","radiolaria",
"coccolithophoridae")) {tp = -15:0} else {tp = -5:0} #optimal delay (tp) values
#test with several delay values
for (i in 1:NROW(comb)) {
vars <- c(comb[i,1], comb[i,2])
params <- expand.grid(lib_column = vars, target_column = vars, tp = tp) # generate all combinations of lib_column, target_column, tp
params <- params[params$lib_column != params$target_column, ] # throw out cases where lib == target
params$E <- best_E[as.vector(params$lib_column)] #embedding dimension
output <- do.call(rbind, lapply(seq_len(NROW(params)), function(i) {
ccm(envsub, E = params$E[i], lib_sizes = NROW(envsub),
random_libs = FALSE, lib_column = params$lib_column[i],
target_column = params$target_column[i],
tp = params$tp[i], silent = TRUE)}))
plot(output$tp[output$lib_column == comb[i,1]],
output$rho[output$lib_column == comb[i,1]],
xlab = "tp", ylab = "Cross Map Skill (rho)", col = "green",
ylim = c(0,1), type = "l", lwd = 2, main = paste(comb[i,1],"<->",comb[i,2]))
lines(output$tp[output$lib_column == comb[i,2]],
output$rho[output$lib_column == comb[i,2]], col = "purple",
lwd = 2)
legend(x = "topleft", col = c("green", "purple"), lwd = 2,
legend = c(paste(comb[i,1]," xmap ",comb[i,2]), paste(comb[i,2],
" xmap ",comb[i,1])),
inset = 0.02, bty = "n", cex = 0.8)
#fill matrices
ccm_rho_matrix[comb[i,1], comb[i,2]] <- max(output$rho[output$lib_column == comb[i,1]],
na.rm=TRUE)
ccm_tp_matrix[comb[i,1], comb[i,2]] <- output$tp[output$rho == ccm_rho_matrix[comb[i,1],
comb[i,2]] & !is.na(output$rho)]
}
#ccm analyses and significance test with surrogate data
for (i in 1:NROW(comb)) {
out_temp <- ccm(envsub, E = best_E[comb[i,1]], lib_column = comb[i,1], #ccm
target_column = comb[i,2], lib_sizes = NROW(envsub),
tp = ccm_tp_matrix[comb[i,1], comb[i,2]],
replace = FALSE, silent = TRUE)
ccm_rho_matrix[comb[i,1], comb[i,2]] <- out_temp$rho #fill matrix
#significance test
num_surr <- 1000 #number of runs
partialdat <- data.frame(envsub[comb[i,1]],envsub[comb[i,2]])
names(partialdat) <-comb[i,]
partialdat <- partialdat[complete.cases(partialdat), ]
surr_a <- make_surrogate_data(partialdat[comb[i,2]], method = "ebisuzaki",
num_surr = num_surr)
ccm_rho_surr <- numeric(num_surr)
for (j in 1:num_surr) {
ccm_rho_surr[j] <- ccm(cbind(partialdat[comb[i,1]], surr_a[,j]),
E = best_E[comb[i,1]], lib_column = 1,
tp = ccm_tp_matrix[comb[i,1], comb[i,2]],
target_column = 2, lib_sizes = NROW(envsub),
replace = FALSE, silent = TRUE)$rho
}
#p-values computation
ccm_rho_pvalues_matrix[comb[i,1], comb[i,2]] <- (sum(ccm_rho_matrix[comb[i,1],
comb[i,2]] < ccm_rho_surr) + 1) / (length(ccm_rho_surr) + 1)
}
#convergence test
for (i in 1:NROW(comb)) {
#cross-maps
inv_xmap_no <- ccm(envsub, lib_column = comb[i,1], target_column = comb[i,2], #lib_column cause
E = best_E[comb[i,1]], tp = ccm_tp_matrix[comb[i,1], comb[i,2]], silent = TRUE)                       #target_column consequence
no_xmap_inv <- ccm(envsub, lib_column = comb[i,2], target_column = comb[i,1],
E = best_E[comb[i,2]], tp = ccm_tp_matrix[comb[i,1], comb[i,2]], silent = TRUE)
inv_xmap_no_means <- ccm_means(inv_xmap_no) #means for different library sizes
no_xmap_inv_means <- ccm_means(no_xmap_inv)#moyennes pour diffÃ©rentes library sizes
#convergence test
kendallconv <- cor.test(inv_xmap_no_means$lib_size, pmax(0, inv_xmap_no_means$rho), method = "kendall")
if (is.na(kendallconv$estimate) | kendallconv$estimate < 0) {ccm_rho_converg[comb[i,1], comb[i,2]] <- 0.99
} else  {ccm_rho_converg[comb[i,1], comb[i,2]] <- kendallconv$p.value}
}
ccm_rho_ptot <- ccm_rho_pvalues_matrix
for (i in NROW(ccm_rho_ptot)) {for (j in NCOL(ccm_rho_ptot)) {
ccm_rho_ptot[i,j] <- max(ccm_rho_pvalues_matrix[i,j],ccm_rho_converg[i,j])
}}
#save matrices
write.table(ccm_rho_matrix,paste("rho_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
write.table(ccm_rho_pvalues_matrix,paste("pval_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
write.table(ccm_rho_converg,paste("converg_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
write.table(ccm_tp_matrix,paste("tp_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
scr = "coccolithophoridae"
taxdb_path <- paste(substr(getSourceEditorContext()$path,1,35),
"datasets/taxonomic_databases/",scr,"/", sep="")
setwd(dir = taxdb_path) #set path
load("savevar.RData")
envsub <- env[,2:NCOL(env)]
envsub <- rawdataset <- as.data.frame(scale(envsub))
causalvars <- names(envsub)
effectvars <- causalvars[1:3]
simplex_out <- lapply(causalvars, function(var) {
simplex(envsub[,var], E = 0:10)
})
names(simplex_out) <- causalvars
par(mfrow = c(3, 3))
for (var in names(simplex_out)) {
plot(simplex_out[[var]]$E, simplex_out[[var]]$rho, type = "l",
xlab = "Embedding Dimension (E)",
ylab = "Forecast Skill (rho)", main = var)
}
best_E <- sapply(simplex_out, function(df) {
df$E[which.max(df$rho)]
})
ccm_rho_matrix <- matrix(NA, nrow = length(causalvars), ncol = length(effectvars), dimnames = list(causalvars, effectvars))
ccm_rho_pvalues_matrix <- matrix(NA, nrow = length(causalvars), ncol = length(effectvars), dimnames = list(causalvars, effectvars))
ccm_rho_converg <- matrix(NA, nrow = length(causalvars), ncol = length(effectvars), dimnames = list(causalvars, effectvars))
ccm_tp_matrix <- matrix(NA, nrow = length(causalvars), ncol = length(effectvars), dimnames = list(causalvars, effectvars))
comb <- expand.grid(causalvars, effectvars, stringsAsFactors = FALSE)
comb <- comb[comb$Var1 != comb$Var2,]
par(mfrow = c(3, 3))
if (scr %in% c("prymnesiophycae","foraminifera","radiolaria",
"coccolithophoridae")) {tp = -15:0} else {tp = -5:0} #optimal delay (tp) values
#test with several delay values
for (i in 1:NROW(comb)) {
vars <- c(comb[i,1], comb[i,2])
params <- expand.grid(lib_column = vars, target_column = vars, tp = tp) # generate all combinations of lib_column, target_column, tp
params <- params[params$lib_column != params$target_column, ] # throw out cases where lib == target
params$E <- best_E[as.vector(params$lib_column)] #embedding dimension
output <- do.call(rbind, lapply(seq_len(NROW(params)), function(i) {
ccm(envsub, E = params$E[i], lib_sizes = NROW(envsub),
random_libs = FALSE, lib_column = params$lib_column[i],
target_column = params$target_column[i],
tp = params$tp[i], silent = TRUE)}))
plot(output$tp[output$lib_column == comb[i,1]],
output$rho[output$lib_column == comb[i,1]],
xlab = "tp", ylab = "Cross Map Skill (rho)", col = "green",
ylim = c(0,1), type = "l", lwd = 2, main = paste(comb[i,1],"<->",comb[i,2]))
lines(output$tp[output$lib_column == comb[i,2]],
output$rho[output$lib_column == comb[i,2]], col = "purple",
lwd = 2)
legend(x = "topleft", col = c("green", "purple"), lwd = 2,
legend = c(paste(comb[i,1]," xmap ",comb[i,2]), paste(comb[i,2],
" xmap ",comb[i,1])),
inset = 0.02, bty = "n", cex = 0.8)
#fill matrices
ccm_rho_matrix[comb[i,1], comb[i,2]] <- max(output$rho[output$lib_column == comb[i,1]],
na.rm=TRUE)
ccm_tp_matrix[comb[i,1], comb[i,2]] <- output$tp[output$rho == ccm_rho_matrix[comb[i,1],
comb[i,2]] & !is.na(output$rho)]
}
#ccm analyses and significance test with surrogate data
for (i in 1:NROW(comb)) {
out_temp <- ccm(envsub, E = best_E[comb[i,1]], lib_column = comb[i,1], #ccm
target_column = comb[i,2], lib_sizes = NROW(envsub),
tp = ccm_tp_matrix[comb[i,1], comb[i,2]],
replace = FALSE, silent = TRUE)
ccm_rho_matrix[comb[i,1], comb[i,2]] <- out_temp$rho #fill matrix
#significance test
num_surr <- 1000 #number of runs
partialdat <- data.frame(envsub[comb[i,1]],envsub[comb[i,2]])
names(partialdat) <-comb[i,]
partialdat <- partialdat[complete.cases(partialdat), ]
surr_a <- make_surrogate_data(partialdat[comb[i,2]], method = "ebisuzaki",
num_surr = num_surr)
ccm_rho_surr <- numeric(num_surr)
for (j in 1:num_surr) {
ccm_rho_surr[j] <- ccm(cbind(partialdat[comb[i,1]], surr_a[,j]),
E = best_E[comb[i,1]], lib_column = 1,
tp = ccm_tp_matrix[comb[i,1], comb[i,2]],
target_column = 2, lib_sizes = NROW(envsub),
replace = FALSE, silent = TRUE)$rho
}
#p-values computation
ccm_rho_pvalues_matrix[comb[i,1], comb[i,2]] <- (sum(ccm_rho_matrix[comb[i,1],
comb[i,2]] < ccm_rho_surr) + 1) / (length(ccm_rho_surr) + 1)
}
#convergence test
for (i in 1:NROW(comb)) {
#cross-maps
inv_xmap_no <- ccm(envsub, lib_column = comb[i,1], target_column = comb[i,2], #lib_column cause
E = best_E[comb[i,1]], tp = ccm_tp_matrix[comb[i,1], comb[i,2]], silent = TRUE)                       #target_column consequence
no_xmap_inv <- ccm(envsub, lib_column = comb[i,2], target_column = comb[i,1],
E = best_E[comb[i,2]], tp = ccm_tp_matrix[comb[i,1], comb[i,2]], silent = TRUE)
inv_xmap_no_means <- ccm_means(inv_xmap_no) #means for different library sizes
no_xmap_inv_means <- ccm_means(no_xmap_inv)#moyennes pour diffÃ©rentes library sizes
#convergence test
kendallconv <- cor.test(inv_xmap_no_means$lib_size, pmax(0, inv_xmap_no_means$rho), method = "kendall")
if (is.na(kendallconv$estimate) | kendallconv$estimate < 0) {ccm_rho_converg[comb[i,1], comb[i,2]] <- 0.99
} else  {ccm_rho_converg[comb[i,1], comb[i,2]] <- kendallconv$p.value}
}
ccm_rho_ptot <- ccm_rho_pvalues_matrix
for (i in NROW(ccm_rho_ptot)) {for (j in NCOL(ccm_rho_ptot)) {
ccm_rho_ptot[i,j] <- max(ccm_rho_pvalues_matrix[i,j],ccm_rho_converg[i,j])
}}
#save matrices
write.table(ccm_rho_matrix,paste("rho_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
write.table(ccm_rho_pvalues_matrix,paste("pval_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
write.table(ccm_rho_converg,paste("converg_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
write.table(ccm_tp_matrix,paste("tp_matrix.csv", sep = ""),
row.names = TRUE, quote=FALSE,sep=" ")
